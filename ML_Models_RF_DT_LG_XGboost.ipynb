{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Ce1OZgvRGSwV3T0iK4nSqT2bVujGdRts",
      "authorship_tag": "ABX9TyOeCZDLOMwux3F/BUco6TRQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khalidaman9555/IDS-AI/blob/main/ML_Models_RF_DT_LG_XGboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UU8BSIeuLqH",
        "outputId": "4791bdd6-bb11-4128-a03d-a5e4b5a1a4aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset: /content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv\n",
            "Dataset loaded successfully.\n",
            "Initial dataset shape: (157800, 63)\n",
            "Dataset shape after dropping NA: (157800, 63)\n",
            "Selected features for training: ['arp.hw.size', 'http.content_length', 'http.response', 'http.tls_port', 'tcp.ack_raw', 'tcp.checksum', 'tcp.connection.fin', 'tcp.connection.rst', 'tcp.connection.syn', 'tcp.connection.synack', 'tcp.dstport', 'tcp.flags.ack', 'tcp.len', 'udp.stream', 'udp.time_delta', 'dns.qry.qu', 'dns.qry.type', 'dns.retransmission', 'dns.retransmit_request', 'dns.retransmit_request_in', 'mqtt.conflag.cleansess', 'mqtt.hdrflags', 'mqtt.len', 'mqtt.msg_decoded_as', 'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id']\n",
            "Number of selected features: 27\n",
            "Training set size: 110460\n",
            "Validation set size: 23670\n",
            "Test set size: 23670\n",
            "Feature scaling complete.\n",
            "Scaler saved to /content/drive/MyDrive/Colab Notebooks/results/common_scaler.joblib\n",
            "Scaler saved to /content/drive/MyDrive/Colab Notebooks/results/common_scaler.pkl\n",
            "\n",
            "--- Training RandomForest ---\n",
            "RandomForest training complete.\n",
            "Saved RandomForest to /content/drive/MyDrive/Colab Notebooks/results/randomforest_model.joblib\n",
            "Saved RandomForest to /content/drive/MyDrive/Colab Notebooks/results/randomforest_model.pkl\n",
            "Saved RandomForest and scaler to /content/drive/MyDrive/Colab Notebooks/results/randomforest_model_and_scaler.h5\n",
            "\n",
            "RandomForest Validation Accuracy: 0.9728\n",
            "RandomForest Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91      3645\n",
            "           1       0.98      0.99      0.98     20025\n",
            "\n",
            "    accuracy                           0.97     23670\n",
            "   macro avg       0.95      0.94      0.95     23670\n",
            "weighted avg       0.97      0.97      0.97     23670\n",
            "\n",
            "\n",
            "RandomForest Test Accuracy: 0.9762\n",
            "RandomForest Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92      3645\n",
            "           1       0.98      0.99      0.99     20025\n",
            "\n",
            "    accuracy                           0.98     23670\n",
            "   macro avg       0.96      0.95      0.95     23670\n",
            "weighted avg       0.98      0.98      0.98     23670\n",
            "\n",
            "\n",
            "--- Training DecisionTree ---\n",
            "DecisionTree training complete.\n",
            "Saved DecisionTree to /content/drive/MyDrive/Colab Notebooks/results/decisiontree_model.joblib\n",
            "Saved DecisionTree to /content/drive/MyDrive/Colab Notebooks/results/decisiontree_model.pkl\n",
            "Saved DecisionTree and scaler to /content/drive/MyDrive/Colab Notebooks/results/decisiontree_model_and_scaler.h5\n",
            "\n",
            "DecisionTree Validation Accuracy: 0.9694\n",
            "DecisionTree Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90      3645\n",
            "           1       0.98      0.98      0.98     20025\n",
            "\n",
            "    accuracy                           0.97     23670\n",
            "   macro avg       0.94      0.94      0.94     23670\n",
            "weighted avg       0.97      0.97      0.97     23670\n",
            "\n",
            "\n",
            "DecisionTree Test Accuracy: 0.9713\n",
            "DecisionTree Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.91      0.91      3645\n",
            "           1       0.98      0.98      0.98     20025\n",
            "\n",
            "    accuracy                           0.97     23670\n",
            "   macro avg       0.95      0.94      0.94     23670\n",
            "weighted avg       0.97      0.97      0.97     23670\n",
            "\n",
            "\n",
            "--- Training LogisticRegression ---\n",
            "LogisticRegression training complete.\n",
            "Saved LogisticRegression to /content/drive/MyDrive/Colab Notebooks/results/logisticregression_model.joblib\n",
            "Saved LogisticRegression to /content/drive/MyDrive/Colab Notebooks/results/logisticregression_model.pkl\n",
            "Saved LogisticRegression and scaler to /content/drive/MyDrive/Colab Notebooks/results/logisticregression_model_and_scaler.h5\n",
            "\n",
            "LogisticRegression Validation Accuracy: 0.8777\n",
            "LogisticRegression Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.21      0.34      3645\n",
            "           1       0.87      1.00      0.93     20025\n",
            "\n",
            "    accuracy                           0.88     23670\n",
            "   macro avg       0.94      0.60      0.64     23670\n",
            "weighted avg       0.89      0.88      0.84     23670\n",
            "\n",
            "\n",
            "LogisticRegression Test Accuracy: 0.8818\n",
            "LogisticRegression Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.23      0.38      3645\n",
            "           1       0.88      1.00      0.93     20025\n",
            "\n",
            "    accuracy                           0.88     23670\n",
            "   macro avg       0.94      0.62      0.66     23670\n",
            "weighted avg       0.90      0.88      0.85     23670\n",
            "\n",
            "\n",
            "--- Training XGBoost ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:47:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost training complete.\n",
            "Saved XGBoost to /content/drive/MyDrive/Colab Notebooks/results/xgboost_model.joblib\n",
            "Saved XGBoost to /content/drive/MyDrive/Colab Notebooks/results/xgboost_model.pkl\n",
            "Saved XGBoost and scaler to /content/drive/MyDrive/Colab Notebooks/results/xgboost_model_and_scaler.h5\n",
            "\n",
            "XGBoost Validation Accuracy: 0.9743\n",
            "XGBoost Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.91      0.92      3645\n",
            "           1       0.98      0.99      0.98     20025\n",
            "\n",
            "    accuracy                           0.97     23670\n",
            "   macro avg       0.95      0.95      0.95     23670\n",
            "weighted avg       0.97      0.97      0.97     23670\n",
            "\n",
            "\n",
            "XGBoost Test Accuracy: 0.9775\n",
            "XGBoost Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93      3645\n",
            "           1       0.98      0.99      0.99     20025\n",
            "\n",
            "    accuracy                           0.98     23670\n",
            "   macro avg       0.96      0.95      0.96     23670\n",
            "weighted avg       0.98      0.98      0.98     23670\n",
            "\n",
            "\n",
            "All model results saved to /content/drive/MyDrive/Colab Notebooks/results/classification_models_results.txt\n",
            "\n",
            "Script finished successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Model-specific imports\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier # Make sure xgboost is installed: pip install xgboost\n",
        "\n",
        "import os\n",
        "import joblib\n",
        "import pickle\n",
        "import h5py\n",
        "\n",
        "# --- Configuration ---\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/Colab Notebooks/results\"\n",
        "RESULTS_FILE_PATH = os.path.join(OUTPUT_PATH, \"classification_models_results.txt\")\n",
        "\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "# --- Load Dataset ---\n",
        "print(f\"Loading dataset: {DATASET_PATH}\")\n",
        "df = pd.read_csv(DATASET_PATH, low_memory=False)\n",
        "print(\"Dataset loaded successfully.\")\n",
        "print(f\"Initial dataset shape: {df.shape}\")\n",
        "\n",
        "# --- Preprocessing ---\n",
        "df.replace([float(\"inf\"), float(\"-inf\")], pd.NA, inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "print(f\"Dataset shape after dropping NA: {df.shape}\")\n",
        "\n",
        "if df.empty:\n",
        "    print(\"Dataset is empty after dropping NA values. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "# --- Feature Selection (Consistent with previous script) ---\n",
        "drop_cols = [\"frame.time\", \"ip.src_host\", \"ip.dst_host\", \"arp.src.proto_ipv4\",\n",
        "             \"arp.dst.proto_ipv4\", \"http.file_data\", \"http.request.full_uri\",\n",
        "             \"icmp.transmit_timestamp\", \"tcp.options\", \"tcp.payload\",\n",
        "             \"mqtt.conack.flags\", \"mqtt.msg\", \"mqtt.protoname\", \"mqtt.topic\",\n",
        "             \"mqtt.uuid\", \"mqtt.conflags\",\n",
        "             # \"Attack_label\", \"Attack_type\", \"Label\", # These are handled separately or are targets\n",
        "             \"icmp.unused\", \"http.request.method\", \"http.referer\", \"http.request.version\",\n",
        "             \"dns.qry.name\", \"dns.resp.name\", \"tcp.flags\", \"udp.port\", \"tcp.port\",\n",
        "             \"mqtt.conack.flags_tree\",\n",
        "             \"tcp.options.mss\", \"tcp.window_size\", \"tcp.hdr_len\", \"tcp.seq\", \"tcp.ack\",\n",
        "             \"ip.src\", \"ip.dst\", \"arp.opcode\", \"arp.hw.type\", \"arp.src.hw_mac\",\n",
        "             \"arp.dst.hw_mac\", \"icmp.type\", \"icmp.code\", \"icmp.checksum\",\n",
        "             \"icmp.ident\", \"icmp.seq_le\", \"udp.srcport\", \"udp.dstport\", \"udp.checksum\",\n",
        "             \"dns.id\", \"dns.flags.response\", \"dns.flags.opcode\", \"dns.flags.authoritative\",\n",
        "             \"dns.flags.truncated\", \"dns.flags.recursion_desired\", \"dns.flags.recursion_available\",\n",
        "             \"dns.flags.z\", \"dns.flags.authenticated\", \"dns.flags.checking_disabled\", \"dns.flags.rcode\",\n",
        "             \"dns.count.queries\", \"dns.count.answers\", \"dns.count.auth_rr\", \"dns.count.add_rr\",\n",
        "             \"mqtt.clientid\", \"mqtt.qos\", \"mqtt.retain\", \"mqtt.dupflag\", \"mqtt.sessionpresent\",\n",
        "             \"mqtt.proto_len\", \"mqtt.topic_len\", \"mqtt.ver\", \"mqtt.willmsg\", \"mqtt.willtopic\",\n",
        "             \"mqtt.dup\", \"mqtt.msgtype\", \"mqtt.kalive\", \"mqtt.msgid\", \"mqtt.password\",\n",
        "             \"mqtt.username\", \"mqtt.client_id_len\",\n",
        "             \"mqtt.topic_val\", \"mqtt.msg_len\",\n",
        "             \"mqtt.payload\", \"mqtt.ciphersuite\", \"mqtt.pk_id\", \"mqtt.reason_code\", \"mqtt.session_expiry_interval\",\n",
        "             \"mqtt.will_flag\", \"mqtt.will_qos\", \"mqtt.will_retain\", \"mqtt.will_message_len\", \"mqtt.will_message\",\n",
        "             \"mqtt.will_topic_len\", \"mqtt.will_topic\", \"mqtt.var_header.length\", \"mqtt.var_header.qos\",\n",
        "             \"mqtt.var_header.retain\", \"mqtt.var_header.dup\", \"mqtt.var_header.message_identifier\",\n",
        "             \"mqtt.var_header.topic_name_length\", \"mqtt.var_header.topic_name\", \"mqtt.var_header.packet_identifier\",\n",
        "             \"mqtt.var_header.properties.message_expiry_interval\", \"mqtt.var_header.properties.content_type\",\n",
        "             \"mqtt.var_header.properties.correlation_data\", \"mqtt.var_header.properties.payload_format_indicator\",\n",
        "             \"mqtt.var_header.properties.request_response_information\", \"mqtt.var_header.properties.response_topic\",\n",
        "             \"mqtt.var_header.properties.session_expiry_interval\", \"mqtt.var_header.properties.subscription_identifier\",\n",
        "             \"mqtt.var_header.properties.topic_alias\", \"mqtt.var_header.properties.user_property\",\n",
        "             \"mqtt.var_header.properties.will_delay_interval\", \"mqtt.var_header.properties.will_payload_format_indicator\",\n",
        "             \"mqtt.var_header.properties.will_content_type\", \"mqtt.var_header.properties.will_response_topic\",\n",
        "             \"mqtt.var_header.properties.will_correlation_data\", \"mqtt.var_header.properties.will_user_property\",\n",
        "             \"mqtt.var_header.properties.will_subscription_identifier\", \"mqtt.var_header.properties.will_topic_alias\",\n",
        "             \"mqtt.var_header.properties.will_retained_message\", \"mqtt.var_header.properties.will_message_expiry_interval\",\n",
        "             \"mqtt.var_header.properties.will_content_type_len\", \"mqtt.var_header.properties.will_content_type_val\",\n",
        "             \"mqtt.var_header.properties.will_response_topic_len\", \"mqtt.var_header.properties.will_response_topic_val\",\n",
        "             \"mqtt.var_header.properties.will_correlation_data_len\", \"mqtt.var_header.properties.will_correlation_data_val\",\n",
        "             \"mqtt.var_header.properties.will_user_property_len\", \"mqtt.var_header.properties.will_user_property_val\",\n",
        "             \"mqtt.var_header.properties.will_subscription_identifier_len\", \"mqtt.var_header.properties.will_subscription_identifier_val\",\n",
        "             \"mqtt.var_header.properties.will_topic_alias_len\", \"mqtt.var_header.properties.will_topic_alias_val\",\n",
        "             \"mqtt.var_header.properties.will_retained_message_len\", \"mqtt.var_header.properties.will_retained_message_val\",\n",
        "             \"mqtt.var_header.properties.will_message_expiry_interval_len\", \"mqtt.var_header.properties.will_message_expiry_interval_val\"\n",
        "            ]\n",
        "\n",
        "potential_target_cols = [\"Attack_label\", \"Attack_type\", \"Label\"]\n",
        "cols_to_drop_for_X = sorted(list(set(drop_cols + potential_target_cols)))\n",
        "\n",
        "\n",
        "if \"Attack_label\" not in df.columns:\n",
        "    print(\"Target variable 'Attack_label' not found. Exiting.\")\n",
        "    exit()\n",
        "y = df[\"Attack_label\"]\n",
        "\n",
        "# Create X by dropping specified columns and selecting numeric types\n",
        "X_candidate_features = df.drop(columns=[col for col in cols_to_drop_for_X if col in df.columns], errors=\"ignore\")\n",
        "X = X_candidate_features.select_dtypes(include=np.number)\n",
        "\n",
        "if X.empty:\n",
        "    print(\"No numeric features available after selection. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "feature_names_list = X.columns.tolist() # Save for HDF5 attributes\n",
        "print(f\"Selected features for training: {feature_names_list}\")\n",
        "print(f\"Number of selected features: {len(feature_names_list)}\")\n",
        "\n",
        "# --- Data Splitting ---\n",
        "if y.empty or len(y.unique()) < 2:\n",
        "    print(\"Target variable y is empty or has only one class. Stratified splitting not possible. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=(0.15/0.85), random_state=42, stratify=y_train_val)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Validation set size: {X_val.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n",
        "\n",
        "# --- Feature Scaling ---\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "print(\"Feature scaling complete.\")\n",
        "\n",
        "# Save the scaler (it's common to all models)\n",
        "SCALER_SAVE_PATH_JOBLIB = os.path.join(OUTPUT_PATH, \"common_scaler.joblib\")\n",
        "SCALER_SAVE_PATH_PKL = os.path.join(OUTPUT_PATH, \"common_scaler.pkl\")\n",
        "joblib.dump(scaler, SCALER_SAVE_PATH_JOBLIB)\n",
        "print(f\"Scaler saved to {SCALER_SAVE_PATH_JOBLIB}\")\n",
        "with open(SCALER_SAVE_PATH_PKL, 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print(f\"Scaler saved to {SCALER_SAVE_PATH_PKL}\")\n",
        "\n",
        "# Serialize scaler for HDF5 inclusion\n",
        "scaler_bytes = pickle.dumps(scaler)\n",
        "\n",
        "# --- Master Results String ---\n",
        "all_models_results_summary = \"Classification Models Performance Results:\\n\"\n",
        "all_models_results_summary += f\"Dataset: {DATASET_PATH}\\n\"\n",
        "all_models_results_summary += f\"Number of features used: {len(feature_names_list)}\\n\"\n",
        "all_models_results_summary += f\"Features: {feature_names_list}\\n\\n\"\n",
        "all_models_results_summary += f\"Scaler saved to: {SCALER_SAVE_PATH_JOBLIB}, {SCALER_SAVE_PATH_PKL}\\n\\n\"\n",
        "\n",
        "# --- Model Definitions ---\n",
        "models_to_train = {\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=42, solver='liblinear', max_iter=1000),\n",
        "    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "# --- Iterate Through Models: Train, Evaluate, Save ---\n",
        "for model_name, model_instance in models_to_train.items():\n",
        "    print(f\"\\n--- Training {model_name} ---\")\n",
        "    model_instance.fit(X_train, y_train)\n",
        "    print(f\"{model_name} training complete.\")\n",
        "\n",
        "    # --- Save Model (Joblib, Pickle, HDF5) ---\n",
        "    model_joblib_path = os.path.join(OUTPUT_PATH, f\"{model_name.lower()}_model.joblib\")\n",
        "    model_pkl_path = os.path.join(OUTPUT_PATH, f\"{model_name.lower()}_model.pkl\")\n",
        "    model_h5_path = os.path.join(OUTPUT_PATH, f\"{model_name.lower()}_model_and_scaler.h5\")\n",
        "\n",
        "    # Joblib\n",
        "    joblib.dump(model_instance, model_joblib_path)\n",
        "    print(f\"Saved {model_name} to {model_joblib_path}\")\n",
        "    # Pickle\n",
        "    with open(model_pkl_path, 'wb') as f:\n",
        "        pickle.dump(model_instance, f)\n",
        "    print(f\"Saved {model_name} to {model_pkl_path}\")\n",
        "    # HDF5\n",
        "    try:\n",
        "        model_bytes = pickle.dumps(model_instance)\n",
        "        with h5py.File(model_h5_path, 'w') as h5f:\n",
        "            h5f.create_dataset(f'{model_name.lower()}_model', data=np.void(model_bytes))\n",
        "            h5f.create_dataset('scaler', data=np.void(scaler_bytes)) # Common scaler bytes\n",
        "            h5f.attrs['feature_names'] = feature_names_list # Direct list of strings\n",
        "        print(f\"Saved {model_name} and scaler to {model_h5_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving {model_name} to HDF5 ({model_h5_path}): {e}\")\n",
        "\n",
        "    # --- Evaluate Model ---\n",
        "    # Validation Set\n",
        "    y_val_pred = model_instance.predict(X_val)\n",
        "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "    val_report = classification_report(y_val, y_val_pred, zero_division=0)\n",
        "    print(f\"\\n{model_name} Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    print(f\"{model_name} Validation Classification Report:\\n{val_report}\")\n",
        "\n",
        "    # Test Set\n",
        "    y_test_pred = model_instance.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    test_report = classification_report(y_test, y_test_pred, zero_division=0)\n",
        "    print(f\"\\n{model_name} Test Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"{model_name} Test Classification Report:\\n{test_report}\")\n",
        "\n",
        "    # --- Append to Master Results String ---\n",
        "    all_models_results_summary += f\"--- {model_name} Model Results ---\\n\"\n",
        "    all_models_results_summary += f\"Model saved (joblib): {model_joblib_path}\\n\"\n",
        "    all_models_results_summary += f\"Model saved (pickle): {model_pkl_path}\\n\"\n",
        "    all_models_results_summary += f\"Model & Scaler saved (HDF5): {model_h5_path}\\n\\n\"\n",
        "    all_models_results_summary += f\"Validation Accuracy: {val_accuracy:.4f}\\n\"\n",
        "    all_models_results_summary += f\"Validation Classification Report:\\n{val_report}\\n\\n\"\n",
        "    all_models_results_summary += f\"Test Accuracy: {test_accuracy:.4f}\\n\"\n",
        "    all_models_results_summary += f\"Test Classification Report:\\n{test_report}\\n\"\n",
        "    all_models_results_summary += \"---------------------------------------\\n\\n\"\n",
        "\n",
        "# --- Save Consolidated Results to File ---\n",
        "try:\n",
        "    with open(RESULTS_FILE_PATH, \"w\") as f:\n",
        "        f.write(all_models_results_summary)\n",
        "    print(f\"\\nAll model results saved to {RESULTS_FILE_PATH}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error writing results to file: {e}\")\n",
        "\n",
        "print(\"\\nScript finished successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vyNlCGexvWtB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}