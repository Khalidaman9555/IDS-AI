{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khalidaman9555/IDS-AI/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amViyUTYT16c",
        "outputId": "fb082755-1bcf-4ea2-a34f-0c9ac3ce29d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset found at: /content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-79163c29cf59>:16: DtypeWarning: Columns (3,6,11,13,14,15,16,17,31,32,34,39,45,51,54,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(dataset_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully. Shape: (157800, 63)\n",
            "\n",
            "First 5 rows:\n",
            "  frame.time    ip.src_host ip.dst_host arp.dst.proto_ipv4  arp.opcode  \\\n",
            "0        6.0  192.168.0.152         0.0                0.0         0.0   \n",
            "1        6.0  192.168.0.101         0.0                0.0         0.0   \n",
            "2        6.0  192.168.0.152         0.0                0.0         0.0   \n",
            "3        6.0  192.168.0.101         0.0                0.0         0.0   \n",
            "4        6.0  192.168.0.152         0.0                0.0         0.0   \n",
            "\n",
            "   arp.hw.size arp.src.proto_ipv4  icmp.checksum  icmp.seq_le  \\\n",
            "0          0.0                0.0            0.0          0.0   \n",
            "1          0.0                0.0            0.0          0.0   \n",
            "2          0.0                0.0            0.0          0.0   \n",
            "3          0.0                0.0            0.0          0.0   \n",
            "4          0.0                0.0            0.0          0.0   \n",
            "\n",
            "   icmp.transmit_timestamp  ...  mqtt.proto_len mqtt.protoname  mqtt.topic  \\\n",
            "0                      0.0  ...             0.0            0.0         0.0   \n",
            "1                      0.0  ...             0.0            0.0         0.0   \n",
            "2                      0.0  ...             0.0            0.0         0.0   \n",
            "3                      0.0  ...             0.0            0.0         0.0   \n",
            "4                      0.0  ...             0.0            0.0         0.0   \n",
            "\n",
            "  mqtt.topic_len mqtt.ver mbtcp.len mbtcp.trans_id mbtcp.unit_id  \\\n",
            "0            0.0      0.0       0.0            0.0           0.0   \n",
            "1            0.0      0.0       0.0            0.0           0.0   \n",
            "2            0.0      0.0       0.0            0.0           0.0   \n",
            "3            0.0      0.0       0.0            0.0           0.0   \n",
            "4            0.0      0.0       0.0            0.0           0.0   \n",
            "\n",
            "   Attack_label  Attack_type  \n",
            "0             1         MITM  \n",
            "1             1         MITM  \n",
            "2             1         MITM  \n",
            "3             1         MITM  \n",
            "4             1         MITM  \n",
            "\n",
            "[5 rows x 63 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define dataset path from Google Drive\n",
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv'\n",
        "\n",
        "# Verify file exists\n",
        "if os.path.exists(dataset_path):\n",
        "    print(f\"Dataset found at: {dataset_path}\")\n",
        "    # Load dataset\n",
        "    try:\n",
        "        df = pd.read_csv(dataset_path)\n",
        "        print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
        "        print(\"\\nFirst 5 rows:\")\n",
        "        print(df.head())\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {e}\")\n",
        "else:\n",
        "    print(f\"Error: Dataset not found at {dataset_path}. Please check the path.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSM1RvQeXG-L",
        "outputId": "571215ad-4d59-45d7-f245-a2ea24499ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset found at: /content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv\n",
            "Dataset loaded successfully. Shape: (157800, 63)\n",
            "\n",
            "First 5 rows:\n",
            "  frame.time    ip.src_host ip.dst_host arp.dst.proto_ipv4  arp.opcode  \\\n",
            "0        6.0  192.168.0.152         0.0                0.0         0.0   \n",
            "1        6.0  192.168.0.101         0.0                0.0         0.0   \n",
            "2        6.0  192.168.0.152         0.0                0.0         0.0   \n",
            "3        6.0  192.168.0.101         0.0                0.0         0.0   \n",
            "4        6.0  192.168.0.152         0.0                0.0         0.0   \n",
            "\n",
            "   arp.hw.size arp.src.proto_ipv4  icmp.checksum  icmp.seq_le  \\\n",
            "0          0.0                0.0            0.0          0.0   \n",
            "1          0.0                0.0            0.0          0.0   \n",
            "2          0.0                0.0            0.0          0.0   \n",
            "3          0.0                0.0            0.0          0.0   \n",
            "4          0.0                0.0            0.0          0.0   \n",
            "\n",
            "   icmp.transmit_timestamp  ...  mqtt.proto_len mqtt.protoname  mqtt.topic  \\\n",
            "0                      0.0  ...             0.0            0.0         0.0   \n",
            "1                      0.0  ...             0.0            0.0         0.0   \n",
            "2                      0.0  ...             0.0            0.0         0.0   \n",
            "3                      0.0  ...             0.0            0.0         0.0   \n",
            "4                      0.0  ...             0.0            0.0         0.0   \n",
            "\n",
            "  mqtt.topic_len mqtt.ver mbtcp.len mbtcp.trans_id mbtcp.unit_id  \\\n",
            "0            0.0      0.0       0.0            0.0           0.0   \n",
            "1            0.0      0.0       0.0            0.0           0.0   \n",
            "2            0.0      0.0       0.0            0.0           0.0   \n",
            "3            0.0      0.0       0.0            0.0           0.0   \n",
            "4            0.0      0.0       0.0            0.0           0.0   \n",
            "\n",
            "   Attack_label  Attack_type  \n",
            "0             1         MITM  \n",
            "1             1         MITM  \n",
            "2             1         MITM  \n",
            "3             1         MITM  \n",
            "4             1         MITM  \n",
            "\n",
            "[5 rows x 63 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv'\n",
        "\n",
        "# Verify file exists\n",
        "if os.path.exists(dataset_path):\n",
        "    print(f\"Dataset found at: {dataset_path}\")\n",
        "    # Load dataset with low_memory=False\n",
        "    try:\n",
        "        df = pd.read_csv(dataset_path, low_memory=False)\n",
        "        print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
        "        print(\"\\nFirst 5 rows:\")\n",
        "        print(df.head())\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {e}\")\n",
        "else:\n",
        "    print(f\"Error: Dataset not found at {dataset_path}. Please check the path.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F86B2nEjVfM1",
        "outputId": "ff09c775-5a83-4142-ebce-1aa0d2b65345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset found at: /content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv\n",
            "Dataset loaded successfully. Shape: (157800, 63)\n",
            "\n",
            "First 5 rows:\n",
            "  frame.time    ip.src_host ip.dst_host arp.dst.proto_ipv4  arp.opcode  \\\n",
            "0        6.0  192.168.0.152         0.0                0.0         0.0   \n",
            "1        6.0  192.168.0.101         0.0                0.0         0.0   \n",
            "2        6.0  192.168.0.152         0.0                0.0         0.0   \n",
            "3        6.0  192.168.0.101         0.0                0.0         0.0   \n",
            "4        6.0  192.168.0.152         0.0                0.0         0.0   \n",
            "\n",
            "   arp.hw.size arp.src.proto_ipv4  icmp.checksum  icmp.seq_le  \\\n",
            "0          0.0                0.0            0.0          0.0   \n",
            "1          0.0                0.0            0.0          0.0   \n",
            "2          0.0                0.0            0.0          0.0   \n",
            "3          0.0                0.0            0.0          0.0   \n",
            "4          0.0                0.0            0.0          0.0   \n",
            "\n",
            "   icmp.transmit_timestamp  ...  mqtt.proto_len mqtt.protoname  mqtt.topic  \\\n",
            "0                      0.0  ...             0.0            0.0         0.0   \n",
            "1                      0.0  ...             0.0            0.0         0.0   \n",
            "2                      0.0  ...             0.0            0.0         0.0   \n",
            "3                      0.0  ...             0.0            0.0         0.0   \n",
            "4                      0.0  ...             0.0            0.0         0.0   \n",
            "\n",
            "  mqtt.topic_len mqtt.ver mbtcp.len mbtcp.trans_id mbtcp.unit_id  \\\n",
            "0            0.0      0.0       0.0            0.0           0.0   \n",
            "1            0.0      0.0       0.0            0.0           0.0   \n",
            "2            0.0      0.0       0.0            0.0           0.0   \n",
            "3            0.0      0.0       0.0            0.0           0.0   \n",
            "4            0.0      0.0       0.0            0.0           0.0   \n",
            "\n",
            "   Attack_label  Attack_type  \n",
            "0             1         MITM  \n",
            "1             1         MITM  \n",
            "2             1         MITM  \n",
            "3             1         MITM  \n",
            "4             1         MITM  \n",
            "\n",
            "[5 rows x 63 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define dataset path from Google Drive\n",
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/datasets/ML-EdgeIIoT-dataset.csv'\n",
        "\n",
        "# Verify file exists\n",
        "if os.path.exists(dataset_path):\n",
        "    print(f\"Dataset found at: {dataset_path}\")\n",
        "    # Load dataset with low_memory=False\n",
        "    try:\n",
        "        df = pd.read_csv(dataset_path, low_memory=False)\n",
        "        print(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
        "        print(\"\\nFirst 5 rows:\")\n",
        "        print(df.head())\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {e}\")\n",
        "else:\n",
        "    print(f\"Error: Dataset not found at {dataset_path}. Please check the path.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhw2Oyc0WGE6",
        "outputId": "3b08242c-2fd5-4fc3-a38d-f2e8149a03b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 157800 entries, 0 to 157799\n",
            "Data columns (total 63 columns):\n",
            " #   Column                     Non-Null Count   Dtype  \n",
            "---  ------                     --------------   -----  \n",
            " 0   frame.time                 157800 non-null  object \n",
            " 1   ip.src_host                157800 non-null  object \n",
            " 2   ip.dst_host                157800 non-null  object \n",
            " 3   arp.dst.proto_ipv4         157800 non-null  object \n",
            " 4   arp.opcode                 157800 non-null  float64\n",
            " 5   arp.hw.size                157800 non-null  float64\n",
            " 6   arp.src.proto_ipv4         157800 non-null  object \n",
            " 7   icmp.checksum              157800 non-null  float64\n",
            " 8   icmp.seq_le                157800 non-null  float64\n",
            " 9   icmp.transmit_timestamp    157800 non-null  float64\n",
            " 10  icmp.unused                157800 non-null  float64\n",
            " 11  http.file_data             157800 non-null  object \n",
            " 12  http.content_length        157800 non-null  float64\n",
            " 13  http.request.uri.query     157800 non-null  object \n",
            " 14  http.request.method        157800 non-null  object \n",
            " 15  http.referer               157800 non-null  object \n",
            " 16  http.request.full_uri      157800 non-null  object \n",
            " 17  http.request.version       157800 non-null  object \n",
            " 18  http.response              157800 non-null  float64\n",
            " 19  http.tls_port              157800 non-null  float64\n",
            " 20  tcp.ack                    157800 non-null  float64\n",
            " 21  tcp.ack_raw                157800 non-null  float64\n",
            " 22  tcp.checksum               157800 non-null  float64\n",
            " 23  tcp.connection.fin         157800 non-null  float64\n",
            " 24  tcp.connection.rst         157800 non-null  float64\n",
            " 25  tcp.connection.syn         157800 non-null  float64\n",
            " 26  tcp.connection.synack      157800 non-null  float64\n",
            " 27  tcp.dstport                157800 non-null  float64\n",
            " 28  tcp.flags                  157800 non-null  float64\n",
            " 29  tcp.flags.ack              157800 non-null  float64\n",
            " 30  tcp.len                    157800 non-null  float64\n",
            " 31  tcp.options                157800 non-null  object \n",
            " 32  tcp.payload                157800 non-null  object \n",
            " 33  tcp.seq                    157800 non-null  float64\n",
            " 34  tcp.srcport                157800 non-null  object \n",
            " 35  udp.port                   157800 non-null  float64\n",
            " 36  udp.stream                 157800 non-null  float64\n",
            " 37  udp.time_delta             157800 non-null  float64\n",
            " 38  dns.qry.name               157800 non-null  float64\n",
            " 39  dns.qry.name.len           157800 non-null  object \n",
            " 40  dns.qry.qu                 157800 non-null  float64\n",
            " 41  dns.qry.type               157800 non-null  float64\n",
            " 42  dns.retransmission         157800 non-null  float64\n",
            " 43  dns.retransmit_request     157800 non-null  float64\n",
            " 44  dns.retransmit_request_in  157800 non-null  float64\n",
            " 45  mqtt.conack.flags          157800 non-null  object \n",
            " 46  mqtt.conflag.cleansess     157800 non-null  float64\n",
            " 47  mqtt.conflags              157800 non-null  float64\n",
            " 48  mqtt.hdrflags              157800 non-null  float64\n",
            " 49  mqtt.len                   157800 non-null  float64\n",
            " 50  mqtt.msg_decoded_as        157800 non-null  float64\n",
            " 51  mqtt.msg                   157800 non-null  object \n",
            " 52  mqtt.msgtype               157800 non-null  float64\n",
            " 53  mqtt.proto_len             157800 non-null  float64\n",
            " 54  mqtt.protoname             157800 non-null  object \n",
            " 55  mqtt.topic                 157800 non-null  object \n",
            " 56  mqtt.topic_len             157800 non-null  float64\n",
            " 57  mqtt.ver                   157800 non-null  float64\n",
            " 58  mbtcp.len                  157800 non-null  float64\n",
            " 59  mbtcp.trans_id             157800 non-null  float64\n",
            " 60  mbtcp.unit_id              157800 non-null  float64\n",
            " 61  Attack_label               157800 non-null  int64  \n",
            " 62  Attack_type                157800 non-null  object \n",
            "dtypes: float64(42), int64(1), object(20)\n",
            "memory usage: 75.8+ MB\n",
            "None\n",
            "arp.opcode has 3 unique values, likely categorical.\n",
            "arp.hw.size has 2 unique values, likely categorical.\n",
            "icmp.unused has 1 unique values, likely categorical.\n",
            "http.response has 2 unique values, likely categorical.\n",
            "http.tls_port has 1 unique values, likely categorical.\n",
            "tcp.connection.fin has 2 unique values, likely categorical.\n",
            "tcp.connection.rst has 2 unique values, likely categorical.\n",
            "tcp.connection.syn has 2 unique values, likely categorical.\n",
            "tcp.connection.synack has 2 unique values, likely categorical.\n",
            "tcp.flags has 9 unique values, likely categorical.\n",
            "tcp.flags.ack has 2 unique values, likely categorical.\n",
            "dns.qry.type has 1 unique values, likely categorical.\n",
            "dns.retransmission has 4 unique values, likely categorical.\n",
            "dns.retransmit_request has 2 unique values, likely categorical.\n",
            "dns.retransmit_request_in has 1 unique values, likely categorical.\n",
            "mqtt.conflag.cleansess has 2 unique values, likely categorical.\n",
            "mqtt.conflags has 2 unique values, likely categorical.\n",
            "mqtt.hdrflags has 5 unique values, likely categorical.\n",
            "mqtt.len has 4 unique values, likely categorical.\n",
            "mqtt.msg_decoded_as has 1 unique values, likely categorical.\n",
            "mqtt.msgtype has 5 unique values, likely categorical.\n",
            "mqtt.proto_len has 2 unique values, likely categorical.\n",
            "mqtt.topic_len has 2 unique values, likely categorical.\n",
            "mqtt.ver has 2 unique values, likely categorical.\n",
            "mbtcp.len has 1 unique values, likely categorical.\n",
            "mbtcp.trans_id has 1 unique values, likely categorical.\n",
            "mbtcp.unit_id has 1 unique values, likely categorical.\n",
            "Attack_label has 2 unique values, likely categorical.\n",
            "\n",
            "Identified Categorical Features (Excluding Targets):\n",
            "['frame.time', 'ip.src_host', 'ip.dst_host', 'arp.dst.proto_ipv4', 'arp.src.proto_ipv4', 'http.file_data', 'http.request.uri.query', 'http.request.method', 'http.referer', 'http.request.full_uri', 'http.request.version', 'tcp.options', 'tcp.payload', 'tcp.srcport', 'dns.qry.name.len', 'mqtt.conack.flags', 'mqtt.msg', 'mqtt.protoname', 'mqtt.topic', 'arp.opcode', 'arp.hw.size', 'icmp.unused', 'http.response', 'http.tls_port', 'tcp.connection.fin', 'tcp.connection.rst', 'tcp.connection.syn', 'tcp.connection.synack', 'tcp.flags', 'tcp.flags.ack', 'dns.qry.type', 'dns.retransmission', 'dns.retransmit_request', 'dns.retransmit_request_in', 'mqtt.conflag.cleansess', 'mqtt.conflags', 'mqtt.hdrflags', 'mqtt.len', 'mqtt.msg_decoded_as', 'mqtt.msgtype', 'mqtt.proto_len', 'mqtt.topic_len', 'mqtt.ver', 'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id']\n",
            "\n",
            "Cardinality of Categorical Features:\n",
            "frame.time: 155186 unique values\n",
            "ip.src_host: 19090 unique values\n",
            "ip.dst_host: 8084 unique values\n",
            "arp.dst.proto_ipv4: 8 unique values\n",
            "arp.src.proto_ipv4: 8 unique values\n",
            "http.file_data: 496 unique values\n",
            "http.request.uri.query: 1665 unique values\n",
            "http.request.method: 6 unique values\n",
            "http.referer: 4 unique values\n",
            "http.request.full_uri: 4073 unique values\n",
            "http.request.version: 8 unique values\n",
            "tcp.options: 73139 unique values\n",
            "tcp.payload: 27369 unique values\n",
            "tcp.srcport: 32186 unique values\n",
            "dns.qry.name.len: 8 unique values\n",
            "mqtt.conack.flags: 3 unique values\n",
            "mqtt.msg: 117 unique values\n",
            "mqtt.protoname: 3 unique values\n",
            "mqtt.topic: 3 unique values\n",
            "arp.opcode: 3 unique values\n",
            "arp.hw.size: 2 unique values\n",
            "icmp.unused: 1 unique values\n",
            "http.response: 2 unique values\n",
            "http.tls_port: 1 unique values\n",
            "tcp.connection.fin: 2 unique values\n",
            "tcp.connection.rst: 2 unique values\n",
            "tcp.connection.syn: 2 unique values\n",
            "tcp.connection.synack: 2 unique values\n",
            "tcp.flags: 9 unique values\n",
            "tcp.flags.ack: 2 unique values\n",
            "dns.qry.type: 1 unique values\n",
            "dns.retransmission: 4 unique values\n",
            "dns.retransmit_request: 2 unique values\n",
            "dns.retransmit_request_in: 1 unique values\n",
            "mqtt.conflag.cleansess: 2 unique values\n",
            "mqtt.conflags: 2 unique values\n",
            "mqtt.hdrflags: 5 unique values\n",
            "mqtt.len: 4 unique values\n",
            "mqtt.msg_decoded_as: 1 unique values\n",
            "mqtt.msgtype: 5 unique values\n",
            "mqtt.proto_len: 2 unique values\n",
            "mqtt.topic_len: 2 unique values\n",
            "mqtt.ver: 2 unique values\n",
            "mbtcp.len: 1 unique values\n",
            "mbtcp.trans_id: 1 unique values\n",
            "mbtcp.unit_id: 1 unique values\n"
          ]
        }
      ],
      "source": [
        "# Identify categorical features\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Select categorical features (object type or low-cardinality integers)\n",
        "categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "# Check numeric features for low-cardinality (potential categorical)\n",
        "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "for col in numeric_features:\n",
        "    unique_count = df[col].nunique()\n",
        "    if unique_count < 20:  # Threshold for categorical-like numeric features\n",
        "        categorical_features.append(col)\n",
        "        print(f\"{col} has {unique_count} unique values, likely categorical.\")\n",
        "\n",
        "# Remove target columns from categorical features\n",
        "target_columns = ['Attack_label', 'Attack_type']\n",
        "categorical_features = [col for col in categorical_features if col not in target_columns]\n",
        "\n",
        "print(\"\\nIdentified Categorical Features (Excluding Targets):\")\n",
        "print(categorical_features)\n",
        "\n",
        "# Assess cardinality for encoding decisions\n",
        "print(\"\\nCardinality of Categorical Features:\")\n",
        "for col in categorical_features:\n",
        "    unique_count = df[col].nunique()\n",
        "    print(f\"{col}: {unique_count} unique values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5GxW8iPWh8_",
        "outputId": "fc29572e-a87b-443d-c48f-97f0cabd2c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.15.2)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCaEo8RIWbbw",
        "outputId": "c7063555-68bf-447a-c658-088a083844e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.15.2)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Error in one-hot encoding: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'\n",
            "\n",
            "Encoded Training Data Shape: (126240, 54)\n",
            "Encoded Test Data Shape: (31560, 54)\n",
            "\n",
            "Training Data Columns:\n",
            "['frame.time', 'ip.src_host', 'ip.dst_host', 'arp.dst.proto_ipv4', 'arp.opcode', 'arp.hw.size', 'arp.src.proto_ipv4', 'icmp.checksum', 'icmp.seq_le', 'icmp.transmit_timestamp', 'http.file_data', 'http.content_length', 'http.request.uri.query', 'http.request.method', 'http.referer', 'http.request.full_uri', 'http.request.version', 'http.response', 'tcp.ack', 'tcp.ack_raw', 'tcp.checksum', 'tcp.connection.fin', 'tcp.connection.rst', 'tcp.connection.syn', 'tcp.connection.synack', 'tcp.dstport', 'tcp.flags', 'tcp.flags.ack', 'tcp.len', 'tcp.options', 'tcp.payload', 'tcp.seq', 'tcp.srcport', 'udp.port', 'udp.stream', 'udp.time_delta', 'dns.qry.name', 'dns.qry.name.len', 'dns.qry.qu', 'dns.retransmission', 'dns.retransmit_request', 'mqtt.conack.flags', 'mqtt.conflag.cleansess', 'mqtt.conflags', 'mqtt.hdrflags', 'mqtt.len', 'mqtt.msg_decoded_as', 'mqtt.msg', 'mqtt.msgtype', 'mqtt.proto_len', 'mqtt.protoname', 'mqtt.topic', 'mqtt.topic_len', 'mqtt.ver']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Install category_encoders if not installed\n",
        "!pip install category_encoders\n",
        "\n",
        "# Define features\n",
        "low_cardinality = [\n",
        "    'arp.dst.proto_ipv4', 'arp.src.proto_ipv4', 'http.request.method', 'http.referer',\n",
        "    'http.request.version', 'dns.qry.name.len', 'mqtt.conack.flags', 'mqtt.protoname',\n",
        "    'mqtt.topic', 'arp.opcode', 'arp.hw.size', 'http.response', 'tcp.connection.fin',\n",
        "    'tcp.connection.rst', 'tcp.connection.syn', 'tcp.connection.synack', 'tcp.flags',\n",
        "    'tcp.flags.ack', 'dns.retransmission', 'dns.retransmit_request', 'mqtt.conflag.cleansess',\n",
        "    'mqtt.conflags', 'mqtt.hdrflags', 'mqtt.len', 'mqtt.msgtype', 'mqtt.proto_len',\n",
        "    'mqtt.topic_len', 'mqtt.ver'\n",
        "]\n",
        "high_cardinality = [\n",
        "    'frame.time', 'ip.src_host', 'ip.dst_host', 'http.file_data', 'http.request.uri.query',\n",
        "    'http.request.full_uri', 'tcp.options', 'tcp.payload', 'tcp.srcport', 'mqtt.msg'\n",
        "]\n",
        "exclude_features = [\n",
        "    'icmp.unused', 'http.tls_port', 'dns.qry.type', 'dns.retransmit_request_in',\n",
        "    'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id'\n",
        "]\n",
        "\n",
        "# Define features and target\n",
        "target_col = 'Attack_label'\n",
        "X = df.drop(columns=[target_col, 'Attack_type'] + exclude_features)\n",
        "y = df[target_col]\n",
        "\n",
        "# Convert low-cardinality features to string\n",
        "for col in low_cardinality:\n",
        "    X[col] = X[col].astype(str)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-hot encoding\n",
        "try:\n",
        "    one_hot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "    if low_cardinality:\n",
        "        one_hot_encoded = one_hot_encoder.fit_transform(X_train[low_cardinality])\n",
        "        print(f\"One-hot encoded shape: {one_hot_encoded.shape}\")\n",
        "        one_hot_columns = one_hot_encoder.get_feature_names_out(low_cardinality)\n",
        "        one_hot_df = pd.DataFrame(one_hot_encoded, columns=one_hot_columns, index=X_train.index)\n",
        "        X_train = pd.concat([X_train.drop(columns=low_cardinality), one_hot_df], axis=1)\n",
        "\n",
        "        # Apply to test data\n",
        "        one_hot_encoded_test = one_hot_encoder.transform(X_test[low_cardinality])\n",
        "        one_hot_df_test = pd.DataFrame(one_hot_encoded_test, columns=one_hot_columns, index=X_test.index)\n",
        "        X_test = pd.concat([X_test.drop(columns=low_cardinality), one_hot_df_test], axis=1)\n",
        "except Exception as e:\n",
        "    print(f\"Error in one-hot encoding: {e}\")\n",
        "\n",
        "# Target encoding\n",
        "try:\n",
        "    target_encoder = TargetEncoder()\n",
        "    if high_cardinality:\n",
        "        X_train[high_cardinality] = target_encoder.fit_transform(X_train[high_cardinality], y_train)\n",
        "        X_test[high_cardinality] = target_encoder.transform(X_test[high_cardinality])\n",
        "except Exception as e:\n",
        "    print(f\"Error in target encoding: {e}\")\n",
        "\n",
        "print(\"\\nEncoded Training Data Shape:\", X_train.shape)\n",
        "print(\"Encoded Test Data Shape:\", X_test.shape)\n",
        "print(\"\\nTraining Data Columns:\")\n",
        "print(X_train.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fKXWfrdXdBa",
        "outputId": "c8636359-8377-47c4-f59b-bf9250415c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unique Values for Low-Cardinality Features:\n",
            "arp.dst.proto_ipv4: 8 unique values - ['0.0' '0' '192.168.0.128' '192.168.0.170' '192.168.0.1' '192.168.0.101'\n",
            " '192.168.0.147' '192.168.0.129']\n",
            "arp.src.proto_ipv4: 8 unique values - ['0.0' '0' '192.168.0.170' '192.168.0.128' '192.168.0.101' '192.168.0.1'\n",
            " '0.0.0.0' '192.168.0.129']\n",
            "http.request.method: 6 unique values - ['0.0' '0' 'GET' 'POST' 'OPTIONS' 'TRACE']\n",
            "http.referer: 4 unique values - ['0.0' '0'\n",
            " '() { _; } >_[$($())] { echo 93e4r0-CVE-2014-6278: true; echo;echo; }'\n",
            " '127.0.0.1']\n",
            "http.request.version: 8 unique values - ['0' '0.0' 'HTTP/1.1' 'HTTP/1.0'\n",
            " 'Src=javascript:alert(\\'Vulnerable\\')><Img Src=\\\\\" HTTP/1.1'\n",
            " '/etc/passwd|?data=Download HTTP/1.1' '-a HTTP/1.1' 'By Dr HTTP/1.1']\n",
            "dns.qry.name.len: 8 unique values - ['0.0' '1.0' '0' '0.debian.pool.ntp.org' '_googlecast._tcp.local'\n",
            " '1.debian.pool.ntp.org' '2.debian.pool.ntp.org' '3.debian.pool.ntp.org']\n",
            "mqtt.conack.flags: 3 unique values - ['0.0' '0' '0x00000000']\n",
            "mqtt.protoname: 3 unique values - ['0.0' '0' 'MQTT']\n",
            "mqtt.topic: 3 unique values - ['0.0' '0' 'Temperature_and_Humidity']\n",
            "arp.opcode: 3 unique values - [0. 1. 2.]\n",
            "arp.hw.size: 2 unique values - [0. 6.]\n",
            "http.response: 2 unique values - [0. 1.]\n",
            "tcp.connection.fin: 2 unique values - [0. 1.]\n",
            "tcp.connection.rst: 2 unique values - [0. 1.]\n",
            "tcp.connection.syn: 2 unique values - [0. 1.]\n",
            "tcp.connection.synack: 2 unique values - [0. 1.]\n",
            "tcp.flags: 9 unique values - [ 0.  2. 20. 24. 16. 17. 18.  4. 25.]\n",
            "tcp.flags.ack: 2 unique values - [0. 1.]\n",
            "dns.retransmission: 4 unique values - [ 0.  1. 12. 28.]\n",
            "dns.retransmit_request: 2 unique values - [0. 1.]\n",
            "mqtt.conflag.cleansess: 2 unique values - [0. 1.]\n",
            "mqtt.conflags: 2 unique values - [0. 2.]\n",
            "mqtt.hdrflags: 5 unique values - [  0.  32.  16. 224.  48.]\n",
            "mqtt.len: 4 unique values - [ 0.  2. 12. 39.]\n",
            "mqtt.msgtype: 5 unique values - [ 0.  2.  1. 14.  3.]\n",
            "mqtt.proto_len: 2 unique values - [0. 4.]\n",
            "mqtt.topic_len: 2 unique values - [ 0. 24.]\n",
            "mqtt.ver: 2 unique values - [0. 4.]\n"
          ]
        }
      ],
      "source": [
        "# Define low-cardinality features (from Step 2)\n",
        "low_cardinality = [\n",
        "    'arp.dst.proto_ipv4', 'arp.src.proto_ipv4', 'http.request.method', 'http.referer',\n",
        "    'http.request.version', 'dns.qry.name.len', 'mqtt.conack.flags', 'mqtt.protoname',\n",
        "    'mqtt.topic', 'arp.opcode', 'arp.hw.size', 'http.response', 'tcp.connection.fin',\n",
        "    'tcp.connection.rst', 'tcp.connection.syn', 'tcp.connection.synack', 'tcp.flags',\n",
        "    'tcp.flags.ack', 'dns.retransmission', 'dns.retransmit_request', 'mqtt.conflag.cleansess',\n",
        "    'mqtt.conflags', 'mqtt.hdrflags', 'mqtt.len', 'mqtt.msgtype', 'mqtt.proto_len',\n",
        "    'mqtt.topic_len', 'mqtt.ver'\n",
        "]\n",
        "\n",
        "# Inspect unique values\n",
        "print(\"\\nUnique Values for Low-Cardinality Features:\")\n",
        "for col in low_cardinality:\n",
        "    unique_vals = df[col].unique()\n",
        "    print(f\"{col}: {len(unique_vals)} unique values - {unique_vals[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9BVjmp-Xykw",
        "outputId": "fb54f822-3589-42bd-cff5-e2f14e444095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unique Values in X_train for Low-Cardinality Features:\n",
            "arp.dst.proto_ipv4: 8 unique values - ['0' '0.0' '192.168.0.128' '192.168.0.170' '192.168.0.1' '192.168.0.147'\n",
            " '192.168.0.101' '192.168.0.129']\n",
            "arp.src.proto_ipv4: 8 unique values - ['0' '0.0' '192.168.0.170' '192.168.0.128' '192.168.0.1' '0.0.0.0'\n",
            " '192.168.0.101' '192.168.0.129']\n",
            "http.request.method: 6 unique values - ['0' 'GET' '0.0' 'POST' 'TRACE' 'OPTIONS']\n",
            "http.referer: 4 unique values - ['0.0' '0' '127.0.0.1'\n",
            " '() { _; } >_[$($())] { echo 93e4r0-CVE-2014-6278: true; echo;echo; }']\n",
            "http.request.version: 7 unique values - ['0' 'HTTP/1.1' 'HTTP/1.0' '0.0'\n",
            " 'Src=javascript:alert(\\'Vulnerable\\')><Img Src=\\\\\" HTTP/1.1'\n",
            " '/etc/passwd|?data=Download HTTP/1.1' '-a HTTP/1.1']\n",
            "dns.qry.name.len: 7 unique values - ['0.0' '0' '1.0' '1.debian.pool.ntp.org' '0.debian.pool.ntp.org'\n",
            " '3.debian.pool.ntp.org' '2.debian.pool.ntp.org']\n",
            "mqtt.conack.flags: 3 unique values - ['0.0' '0' '0x00000000']\n",
            "mqtt.protoname: 3 unique values - ['0.0' '0' 'MQTT']\n",
            "mqtt.topic: 3 unique values - ['0.0' '0' 'Temperature_and_Humidity']\n",
            "arp.opcode: 3 unique values - ['0.0' '1.0' '2.0']\n",
            "arp.hw.size: 2 unique values - ['0.0' '6.0']\n",
            "http.response: 2 unique values - ['0.0' '1.0']\n",
            "tcp.connection.fin: 2 unique values - ['1.0' '0.0']\n",
            "tcp.connection.rst: 2 unique values - ['0.0' '1.0']\n",
            "tcp.connection.syn: 2 unique values - ['0.0' '1.0']\n",
            "tcp.connection.synack: 2 unique values - ['0.0' '1.0']\n",
            "tcp.flags: 9 unique values - ['17.0' '18.0' '24.0' '16.0' '4.0' '20.0' '2.0' '0.0' '25.0']\n",
            "tcp.flags.ack: 2 unique values - ['1.0' '0.0']\n",
            "dns.retransmission: 3 unique values - ['0.0' '1.0' '28.0']\n",
            "dns.retransmit_request: 2 unique values - ['0.0' '1.0']\n",
            "mqtt.conflag.cleansess: 2 unique values - ['0.0' '1.0']\n",
            "mqtt.conflags: 2 unique values - ['0.0' '2.0']\n",
            "mqtt.hdrflags: 5 unique values - ['0.0' '224.0' '48.0' '16.0' '32.0']\n",
            "mqtt.len: 4 unique values - ['0.0' '39.0' '12.0' '2.0']\n",
            "mqtt.msgtype: 5 unique values - ['0.0' '14.0' '3.0' '1.0' '2.0']\n",
            "mqtt.proto_len: 2 unique values - ['0.0' '4.0']\n",
            "mqtt.topic_len: 2 unique values - ['0.0' '24.0']\n",
            "mqtt.ver: 2 unique values - ['0.0' '4.0']\n",
            "One-hot encoded shape: (126240, 104)\n",
            "\n",
            "High-Cardinality Features Before Target Encoding:\n",
            "frame.time: object, Sample: [' 2021 19:18:26.491153000 ', ' 2021 23:11:46.892638000 ', ' 2021 19:35:28.778765000 ', ' 2021 21:42:33.703356000 ', ' 2021 18:05:26.945506000 ']\n",
            "ip.src_host: object, Sample: ['192.168.0.170', '192.168.0.128', '192.168.0.170', '192.168.0.170', '192.168.0.170']\n",
            "ip.dst_host: object, Sample: ['192.168.0.128', '192.168.0.170', '192.168.0.128', '192.168.0.128', '192.168.0.128']\n",
            "http.file_data: object, Sample: ['0', '0.0', '<!--#include virtual=\"/index.jsp\"-->', '0.0', '0']\n",
            "http.request.uri.query: object, Sample: ['0.0', '0.0', '0', '0', '0.0']\n",
            "http.request.full_uri: object, Sample: ['0', '0', 'http://192.168.0.128/DVWA/iisadmpwd/aexp3.htr', '0', 'http://192.168.0.128/DVWA/login.php']\n",
            "tcp.options: object, Sample: ['0101080ae7df59867b544c42', '020405b40402080a4a074aab40861feb01030307', '0101080a3fc0193f494145a3', '0101080a9b250acd9eb29dbe', '0101080ae79c86887b11771b']\n",
            "tcp.payload: object, Sample: ['0', '0', '474554202f445657412f69697361646d7077642f61657870332e68747220485454502f312e310d0a436f6e74656e742d547970653a206170706c69636174696f6e2f782d7777772d666f726d2d75726c656e636f6465640d0a486f73743a203139322e3136382e302e3132380d0a557365722d4167656e743a204d6f7a696c6c612f352e303020284e696b746f2f322e312e3629202845766173696f6e733a4e6f6e65292028546573743a303031343934290d0a436f6e6e656374696f6e3a204b6565702d416c6976650d0a436f6e74656e742d4c656e6774683a2033360d0a0d0a3c212d2d23696e636c756465207669727475616c3d222f696e6465782e6a7370222d2d3e', '0', '474554202f445657412f6c6f67696e2e70687020485454502f312e300d0a486f73743a203139322e3136382e302e3132380d0a557365722d4167656e743a204d6f7a696c6c612f352e3020284879647261290d0a436f6e74656e742d4c656e6774683a20300d0a436f6e74656e742d547970653a206170706c69636174696f6e2f782d7777772d666f726d2d75726c656e636f6465640d0a436f6f6b69653a205048505345535349443d766233766736326d36613575646c6764686467746f346b7476723b2073656375726974793d696d706f737369626c650d0a0d0a']\n",
            "tcp.srcport: object, Sample: ['38872.0', '80.0', '49798.0', '44582.0', '38074.0']\n",
            "mqtt.msg: object, Sample: ['0.0', '0.0', '0.0', '0.0', '0.0']\n",
            "\n",
            "High-Cardinality Features After Target Encoding:\n",
            "frame.time: float64, Sample: [0.8668977763846298, 0.8668977763846298, 0.8668977763846298, 0.8668977763846298, 0.8668977763846298]\n",
            "ip.src_host: float64, Sample: [1.0, 0.8613222799353307, 1.0, 1.0, 1.0]\n",
            "ip.dst_host: float64, Sample: [0.8685691518501918, 1.0, 0.8685691518501918, 0.8685691518501918, 0.8685691518501918]\n",
            "http.file_data: float64, Sample: [1.0, 0.7938923152436032, 1.0, 0.7938923152436032, 1.0]\n",
            "http.request.uri.query: float64, Sample: [0.8243217433220252, 0.8243217433220252, 1.0, 1.0, 0.8243217433220252]\n",
            "http.request.full_uri: float64, Sample: [1.0, 1.0, 0.8668977763846298, 1.0, 1.0]\n",
            "tcp.options: float64, Sample: [0.8668977763846298, 0.8668977763846298, 0.8668977763846298, 0.8668977763846298, 0.8668977763846298]\n",
            "tcp.payload: float64, Sample: [0.7838647906086088, 0.7838647906086088, 0.8668977763846298, 0.7838647906086088, 0.8668977763846298]\n",
            "tcp.srcport: float64, Sample: [0.8772577313735934, 1.0, 0.8534735136687855, 0.8726927508931648, 0.8726927508931648]\n",
            "mqtt.msg: float64, Sample: [1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "Encoded Training Data Shape: (126240, 130)\n",
            "Encoded Test Data Shape: (31560, 130)\n",
            "\n",
            "Training Data Columns:\n",
            "['frame.time', 'ip.src_host', 'ip.dst_host', 'icmp.checksum', 'icmp.seq_le', 'icmp.transmit_timestamp', 'http.file_data', 'http.content_length', 'http.request.uri.query', 'http.request.full_uri', 'tcp.ack', 'tcp.ack_raw', 'tcp.checksum', 'tcp.dstport', 'tcp.len', 'tcp.options', 'tcp.payload', 'tcp.seq', 'tcp.srcport', 'udp.port', 'udp.stream', 'udp.time_delta', 'dns.qry.name', 'dns.qry.qu', 'mqtt.msg_decoded_as', 'mqtt.msg', 'arp.dst.proto_ipv4_0', 'arp.dst.proto_ipv4_0.0', 'arp.dst.proto_ipv4_192.168.0.1', 'arp.dst.proto_ipv4_192.168.0.101', 'arp.dst.proto_ipv4_192.168.0.128', 'arp.dst.proto_ipv4_192.168.0.129', 'arp.dst.proto_ipv4_192.168.0.147', 'arp.dst.proto_ipv4_192.168.0.170', 'arp.src.proto_ipv4_0', 'arp.src.proto_ipv4_0.0', 'arp.src.proto_ipv4_0.0.0.0', 'arp.src.proto_ipv4_192.168.0.1', 'arp.src.proto_ipv4_192.168.0.101', 'arp.src.proto_ipv4_192.168.0.128', 'arp.src.proto_ipv4_192.168.0.129', 'arp.src.proto_ipv4_192.168.0.170', 'http.request.method_0', 'http.request.method_0.0', 'http.request.method_GET', 'http.request.method_OPTIONS', 'http.request.method_POST', 'http.request.method_TRACE', 'http.referer_() { _; } >_[$($())] { echo 93e4r0-CVE-2014-6278: true; echo;echo; }', 'http.referer_0', 'http.referer_0.0', 'http.referer_127.0.0.1', 'http.request.version_-a HTTP/1.1', 'http.request.version_/etc/passwd|?data=Download HTTP/1.1', 'http.request.version_0', 'http.request.version_0.0', 'http.request.version_HTTP/1.0', 'http.request.version_HTTP/1.1', 'http.request.version_Src=javascript:alert(\\'Vulnerable\\')><Img Src=\\\\\" HTTP/1.1', 'dns.qry.name.len_0', 'dns.qry.name.len_0.0', 'dns.qry.name.len_0.debian.pool.ntp.org', 'dns.qry.name.len_1.0', 'dns.qry.name.len_1.debian.pool.ntp.org', 'dns.qry.name.len_2.debian.pool.ntp.org', 'dns.qry.name.len_3.debian.pool.ntp.org', 'mqtt.conack.flags_0', 'mqtt.conack.flags_0.0', 'mqtt.conack.flags_0x00000000', 'mqtt.protoname_0', 'mqtt.protoname_0.0', 'mqtt.protoname_MQTT', 'mqtt.topic_0', 'mqtt.topic_0.0', 'mqtt.topic_Temperature_and_Humidity', 'arp.opcode_0.0', 'arp.opcode_1.0', 'arp.opcode_2.0', 'arp.hw.size_0.0', 'arp.hw.size_6.0', 'http.response_0.0', 'http.response_1.0', 'tcp.connection.fin_0.0', 'tcp.connection.fin_1.0', 'tcp.connection.rst_0.0', 'tcp.connection.rst_1.0', 'tcp.connection.syn_0.0', 'tcp.connection.syn_1.0', 'tcp.connection.synack_0.0', 'tcp.connection.synack_1.0', 'tcp.flags_0.0', 'tcp.flags_16.0', 'tcp.flags_17.0', 'tcp.flags_18.0', 'tcp.flags_2.0', 'tcp.flags_20.0', 'tcp.flags_24.0', 'tcp.flags_25.0', 'tcp.flags_4.0', 'tcp.flags.ack_0.0', 'tcp.flags.ack_1.0', 'dns.retransmission_0.0', 'dns.retransmission_1.0', 'dns.retransmission_28.0', 'dns.retransmit_request_0.0', 'dns.retransmit_request_1.0', 'mqtt.conflag.cleansess_0.0', 'mqtt.conflag.cleansess_1.0', 'mqtt.conflags_0.0', 'mqtt.conflags_2.0', 'mqtt.hdrflags_0.0', 'mqtt.hdrflags_16.0', 'mqtt.hdrflags_224.0', 'mqtt.hdrflags_32.0', 'mqtt.hdrflags_48.0', 'mqtt.len_0.0', 'mqtt.len_12.0', 'mqtt.len_2.0', 'mqtt.len_39.0', 'mqtt.msgtype_0.0', 'mqtt.msgtype_1.0', 'mqtt.msgtype_14.0', 'mqtt.msgtype_2.0', 'mqtt.msgtype_3.0', 'mqtt.proto_len_0.0', 'mqtt.proto_len_4.0', 'mqtt.topic_len_0.0', 'mqtt.topic_len_24.0', 'mqtt.ver_0.0', 'mqtt.ver_4.0']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define features\n",
        "low_cardinality = [\n",
        "    'arp.dst.proto_ipv4', 'arp.src.proto_ipv4', 'http.request.method', 'http.referer',\n",
        "    'http.request.version', 'dns.qry.name.len', 'mqtt.conack.flags', 'mqtt.protoname',\n",
        "    'mqtt.topic', 'arp.opcode', 'arp.hw.size', 'http.response', 'tcp.connection.fin',\n",
        "    'tcp.connection.rst', 'tcp.connection.syn', 'tcp.connection.synack', 'tcp.flags',\n",
        "    'tcp.flags.ack', 'dns.retransmission', 'dns.retransmit_request', 'mqtt.conflag.cleansess',\n",
        "    'mqtt.conflags', 'mqtt.hdrflags', 'mqtt.len', 'mqtt.msgtype', 'mqtt.proto_len',\n",
        "    'mqtt.topic_len', 'mqtt.ver'\n",
        "]\n",
        "high_cardinality = [\n",
        "    'frame.time', 'ip.src_host', 'ip.dst_host', 'http.file_data', 'http.request.uri.query',\n",
        "    'http.request.full_uri', 'tcp.options', 'tcp.payload', 'tcp.srcport', 'mqtt.msg'\n",
        "]\n",
        "exclude_features = [\n",
        "    'icmp.unused', 'http.tls_port', 'dns.qry.type', 'dns.retransmit_request_in',\n",
        "    'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id'\n",
        "]\n",
        "\n",
        "# Define features and target\n",
        "target_col = 'Attack_label'\n",
        "X = df.drop(columns=[target_col, 'Attack_type'] + exclude_features)\n",
        "y = df[target_col]\n",
        "\n",
        "# Convert low-cardinality features to string\n",
        "for col in low_cardinality:\n",
        "    X[col] = X[col].astype(str)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Debug: Check unique values in X_train\n",
        "print(\"\\nUnique Values in X_train for Low-Cardinality Features:\")\n",
        "for col in low_cardinality:\n",
        "    unique_vals = X_train[col].unique()\n",
        "    print(f\"{col}: {len(unique_vals)} unique values - {unique_vals[:10]}\")\n",
        "\n",
        "# One-hot encoding\n",
        "try:\n",
        "    one_hot_encoder = OneHotEncoder(sparse_output=True, handle_unknown='ignore')  # Updated parameter\n",
        "    if low_cardinality:\n",
        "        one_hot_encoded = one_hot_encoder.fit_transform(X_train[low_cardinality])\n",
        "        print(f\"One-hot encoded shape: {one_hot_encoded.shape}\")\n",
        "        one_hot_columns = one_hot_encoder.get_feature_names_out(low_cardinality)\n",
        "        # Convert sparse matrix to dense for DataFrame\n",
        "        one_hot_df = pd.DataFrame.sparse.from_spmatrix(one_hot_encoded, columns=one_hot_columns, index=X_train.index)\n",
        "        X_train = pd.concat([X_train.drop(columns=low_cardinality), one_hot_df], axis=1)\n",
        "\n",
        "        # Apply to test data\n",
        "        one_hot_encoded_test = one_hot_encoder.transform(X_test[low_cardinality])\n",
        "        one_hot_df_test = pd.DataFrame.sparse.from_spmatrix(one_hot_encoded_test, columns=one_hot_columns, index=X_test.index)\n",
        "        X_test = pd.concat([X_test.drop(columns=low_cardinality), one_hot_df_test], axis=1)\n",
        "except Exception as e:\n",
        "    print(f\"Error in one-hot encoding: {e}\")\n",
        "\n",
        "# Target encoding\n",
        "try:\n",
        "    target_encoder = TargetEncoder()\n",
        "    if high_cardinality:\n",
        "        # Check high-cardinality features before encoding\n",
        "        print(\"\\nHigh-Cardinality Features Before Target Encoding:\")\n",
        "        for col in high_cardinality:\n",
        "            print(f\"{col}: {X_train[col].dtype}, Sample: {X_train[col].head().tolist()}\")\n",
        "        X_train[high_cardinality] = target_encoder.fit_transform(X_train[high_cardinality], y_train)\n",
        "        X_test[high_cardinality] = target_encoder.transform(X_test[high_cardinality])\n",
        "        # Check after encoding\n",
        "        print(\"\\nHigh-Cardinality Features After Target Encoding:\")\n",
        "        for col in high_cardinality:\n",
        "            print(f\"{col}: {X_train[col].dtype}, Sample: {X_train[col].head().tolist()}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error in target encoding: {e}\")\n",
        "\n",
        "print(\"\\nEncoded Training Data Shape:\", X_train.shape)\n",
        "print(\"Encoded Test Data Shape:\", X_test.shape)\n",
        "print(\"\\nTraining Data Columns:\")\n",
        "print(X_train.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thjqWJdmY1B1",
        "outputId": "c53f7cf7-ed3a-44b6-e058-8e4bb7b89753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution of Attack_label:\n",
            "Attack_label\n",
            "1    0.84699\n",
            "0    0.15301\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Absolute Counts:\n",
            "Attack_label\n",
            "1    106924\n",
            "0     19316\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check class distribution\n",
        "print(\"\\nClass Distribution of Attack_label:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(\"\\nAbsolute Counts:\")\n",
        "print(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxmQgtqyY6hG",
        "outputId": "96a804c6-f77e-43f6-b726-0ee2156c1cc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution After SMOTE:\n",
            "Attack_label\n",
            "1    0.5\n",
            "0    0.5\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Absolute Counts After SMOTE:\n",
            "Attack_label\n",
            "1    106924\n",
            "0    106924\n",
            "Name: count, dtype: int64\n",
            "\n",
            "SMOTE Training Data Shape: (213848, 130)\n",
            "SMOTE Test Data Shape (unchanged): (31560, 130)\n",
            "\n",
            "SMOTE Training Data Columns:\n",
            "['frame.time', 'ip.src_host', 'ip.dst_host', 'icmp.checksum', 'icmp.seq_le', 'icmp.transmit_timestamp', 'http.file_data', 'http.content_length', 'http.request.uri.query', 'http.request.full_uri', 'tcp.ack', 'tcp.ack_raw', 'tcp.checksum', 'tcp.dstport', 'tcp.len', 'tcp.options', 'tcp.payload', 'tcp.seq', 'tcp.srcport', 'udp.port', 'udp.stream', 'udp.time_delta', 'dns.qry.name', 'dns.qry.qu', 'mqtt.msg_decoded_as', 'mqtt.msg', 'arp.dst.proto_ipv4_0', 'arp.dst.proto_ipv4_0.0', 'arp.dst.proto_ipv4_192.168.0.1', 'arp.dst.proto_ipv4_192.168.0.101', 'arp.dst.proto_ipv4_192.168.0.128', 'arp.dst.proto_ipv4_192.168.0.129', 'arp.dst.proto_ipv4_192.168.0.147', 'arp.dst.proto_ipv4_192.168.0.170', 'arp.src.proto_ipv4_0', 'arp.src.proto_ipv4_0.0', 'arp.src.proto_ipv4_0.0.0.0', 'arp.src.proto_ipv4_192.168.0.1', 'arp.src.proto_ipv4_192.168.0.101', 'arp.src.proto_ipv4_192.168.0.128', 'arp.src.proto_ipv4_192.168.0.129', 'arp.src.proto_ipv4_192.168.0.170', 'http.request.method_0', 'http.request.method_0.0', 'http.request.method_GET', 'http.request.method_OPTIONS', 'http.request.method_POST', 'http.request.method_TRACE', 'http.referer_() { _; } >_[$($())] { echo 93e4r0-CVE-2014-6278: true; echo;echo; }', 'http.referer_0', 'http.referer_0.0', 'http.referer_127.0.0.1', 'http.request.version_-a HTTP/1.1', 'http.request.version_/etc/passwd|?data=Download HTTP/1.1', 'http.request.version_0', 'http.request.version_0.0', 'http.request.version_HTTP/1.0', 'http.request.version_HTTP/1.1', 'http.request.version_Src=javascript:alert(\\'Vulnerable\\')><Img Src=\\\\\" HTTP/1.1', 'dns.qry.name.len_0', 'dns.qry.name.len_0.0', 'dns.qry.name.len_0.debian.pool.ntp.org', 'dns.qry.name.len_1.0', 'dns.qry.name.len_1.debian.pool.ntp.org', 'dns.qry.name.len_2.debian.pool.ntp.org', 'dns.qry.name.len_3.debian.pool.ntp.org', 'mqtt.conack.flags_0', 'mqtt.conack.flags_0.0', 'mqtt.conack.flags_0x00000000', 'mqtt.protoname_0', 'mqtt.protoname_0.0', 'mqtt.protoname_MQTT', 'mqtt.topic_0', 'mqtt.topic_0.0', 'mqtt.topic_Temperature_and_Humidity', 'arp.opcode_0.0', 'arp.opcode_1.0', 'arp.opcode_2.0', 'arp.hw.size_0.0', 'arp.hw.size_6.0', 'http.response_0.0', 'http.response_1.0', 'tcp.connection.fin_0.0', 'tcp.connection.fin_1.0', 'tcp.connection.rst_0.0', 'tcp.connection.rst_1.0', 'tcp.connection.syn_0.0', 'tcp.connection.syn_1.0', 'tcp.connection.synack_0.0', 'tcp.connection.synack_1.0', 'tcp.flags_0.0', 'tcp.flags_16.0', 'tcp.flags_17.0', 'tcp.flags_18.0', 'tcp.flags_2.0', 'tcp.flags_20.0', 'tcp.flags_24.0', 'tcp.flags_25.0', 'tcp.flags_4.0', 'tcp.flags.ack_0.0', 'tcp.flags.ack_1.0', 'dns.retransmission_0.0', 'dns.retransmission_1.0', 'dns.retransmission_28.0', 'dns.retransmit_request_0.0', 'dns.retransmit_request_1.0', 'mqtt.conflag.cleansess_0.0', 'mqtt.conflag.cleansess_1.0', 'mqtt.conflags_0.0', 'mqtt.conflags_2.0', 'mqtt.hdrflags_0.0', 'mqtt.hdrflags_16.0', 'mqtt.hdrflags_224.0', 'mqtt.hdrflags_32.0', 'mqtt.hdrflags_48.0', 'mqtt.len_0.0', 'mqtt.len_12.0', 'mqtt.len_2.0', 'mqtt.len_39.0', 'mqtt.msgtype_0.0', 'mqtt.msgtype_1.0', 'mqtt.msgtype_14.0', 'mqtt.msgtype_2.0', 'mqtt.msgtype_3.0', 'mqtt.proto_len_0.0', 'mqtt.proto_len_4.0', 'mqtt.topic_len_0.0', 'mqtt.topic_len_24.0', 'mqtt.ver_0.0', 'mqtt.ver_4.0']\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "\n",
        "# Apply SMOTE\n",
        "try:\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"\\nClass Distribution After SMOTE:\")\n",
        "    print(pd.Series(y_train_smote).value_counts(normalize=True))\n",
        "    print(\"\\nAbsolute Counts After SMOTE:\")\n",
        "    print(pd.Series(y_train_smote).value_counts())\n",
        "\n",
        "    print(\"\\nSMOTE Training Data Shape:\", X_train_smote.shape)\n",
        "    print(\"SMOTE Test Data Shape (unchanged):\", X_test.shape)\n",
        "    print(\"\\nSMOTE Training Data Columns:\")\n",
        "    print(X_train_smote.columns.tolist())\n",
        "except Exception as e:\n",
        "    print(f\"Error in SMOTE: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bPjGNuaZ1eq",
        "outputId": "478142e8-58a8-4a84-8b2c-fa8813dc7e63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution of Attack_label:\n",
            "Attack_label\n",
            "1    0.84699\n",
            "0    0.15301\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Absolute Counts:\n",
            "Attack_label\n",
            "1    106924\n",
            "0     19316\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nClass Distribution of Attack_label:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(\"\\nAbsolute Counts:\")\n",
        "print(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-r_THZyY-l9",
        "outputId": "6b633401-9ab6-45df-cbc3-748c5619fc3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (from imblearn) (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
            "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Installing collected packages: imblearn\n",
            "Successfully installed imblearn-0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8Xs605wZ59S",
        "outputId": "a7c26e06-61a4-4f16-d30a-d8757426ccce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Random Forest:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "FPR: 0.0000\n",
            "FNR: 0.0000\n",
            "Confusion Matrix:\n",
            "[[ 4985     0]\n",
            " [    0 26575]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Decision Tree:\n",
            "Accuracy: 0.8420\n",
            "Precision: 0.8420\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9143\n",
            "FPR: 1.0000\n",
            "FNR: 0.0000\n",
            "Confusion Matrix:\n",
            "[[    0  4985]\n",
            " [    0 26575]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for KNN:\n",
            "Accuracy: 0.8032\n",
            "Precision: 0.9378\n",
            "Recall: 0.8207\n",
            "F1-Score: 0.8753\n",
            "FPR: 0.2901\n",
            "FNR: 0.1793\n",
            "Confusion Matrix:\n",
            "[[ 3539  1446]\n",
            " [ 4766 21809]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/data.py:575: UserWarning: Sparse arrays from pandas are converted into dense.\n",
            "  warnings.warn(\"Sparse arrays from pandas are converted into dense.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Logistic Regression:\n",
            "Accuracy: 0.5849\n",
            "Precision: 0.9864\n",
            "Recall: 0.5141\n",
            "F1-Score: 0.6760\n",
            "FPR: 0.0377\n",
            "FNR: 0.4859\n",
            "Confusion Matrix:\n",
            "[[ 4797   188]\n",
            " [12912 13663]]\n",
            "Error training XGBoost: feature_names must be string, and may not contain [, ] or <\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.6145 - loss: 3005981.2500 - val_accuracy: 9.3524e-04 - val_loss: 1.6305\n",
            "Epoch 2/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6312 - loss: 1985.3290 - val_accuracy: 9.3524e-04 - val_loss: 1.7549\n",
            "Epoch 3/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6279 - loss: 581.3385 - val_accuracy: 0.0054 - val_loss: 1.8344\n",
            "Epoch 4/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6267 - loss: 166.5046 - val_accuracy: 0.0054 - val_loss: 1.6752\n",
            "Epoch 5/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6267 - loss: 75.7253 - val_accuracy: 0.0054 - val_loss: 1.6372\n",
            "Epoch 6/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 161.2055 - val_accuracy: 0.0054 - val_loss: 0.9603\n",
            "Epoch 7/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6250 - loss: 45.0781 - val_accuracy: 0.0054 - val_loss: 0.8879\n",
            "Epoch 8/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6257 - loss: 9.2729 - val_accuracy: 0.0054 - val_loss: 0.9404\n",
            "Epoch 9/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6283 - loss: 120.2158 - val_accuracy: 0.0044 - val_loss: 0.9109\n",
            "Epoch 10/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6261 - loss: 6.8972 - val_accuracy: 0.0044 - val_loss: 0.8121\n",
            "Epoch 11/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6254 - loss: 9.5020 - val_accuracy: 0.0044 - val_loss: 0.8943\n",
            "Epoch 12/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6244 - loss: 32.5356 - val_accuracy: 0.0044 - val_loss: 0.9746\n",
            "Epoch 13/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6252 - loss: 4.4975 - val_accuracy: 0.0044 - val_loss: 0.8140\n",
            "Epoch 14/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6267 - loss: 8.6591 - val_accuracy: 0.0044 - val_loss: 0.8001\n",
            "Epoch 15/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6278 - loss: 0.5999 - val_accuracy: 0.0045 - val_loss: 0.8149\n",
            "Epoch 16/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6248 - loss: 0.5870 - val_accuracy: 0.0044 - val_loss: 0.8448\n",
            "Epoch 17/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.6264 - loss: 4.8369 - val_accuracy: 0.0044 - val_loss: 0.9570\n",
            "Epoch 18/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.6275 - loss: 9.1374 - val_accuracy: 0.0044 - val_loss: 0.8126\n",
            "Epoch 19/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6265 - loss: 11.5701 - val_accuracy: 0.0044 - val_loss: 0.8451\n",
            "Epoch 20/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.6273 - loss: 55.4319 - val_accuracy: 0.0044 - val_loss: 0.8330\n",
            "\u001b[1m987/987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\n",
            "Results for DNN:\n",
            "Accuracy: 0.8428\n",
            "Precision: 0.8427\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9146\n",
            "FPR: 0.9950\n",
            "FNR: 0.0000\n",
            "Confusion Matrix:\n",
            "[[   25  4960]\n",
            " [    0 26575]]\n",
            "\n",
            "Summary of Results:\n",
            "                 Model  Accuracy  Precision    Recall  F1-Score       FPR  \\\n",
            "0        Random Forest  1.000000   1.000000  1.000000  1.000000  0.000000   \n",
            "1        Decision Tree  0.842047   0.842047  1.000000  0.914251  1.000000   \n",
            "2                  KNN  0.803169   0.937820  0.820659  0.875336  0.290070   \n",
            "3  Logistic Regression  0.584918   0.986427  0.514130  0.675951  0.037713   \n",
            "4                  DNN  0.842839   0.842714  1.000000  0.914645  0.994985   \n",
            "\n",
            "        FNR  \n",
            "0  0.000000  \n",
            "1  0.000000  \n",
            "2  0.179341  \n",
            "3  0.485870  \n",
            "4  0.000000  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    try:\n",
        "        # Train\n",
        "        model.fit(X_train_smote, y_train_smote)\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test)\n",
        "        # Metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1-Score': f1,\n",
        "            'FPR': fpr,\n",
        "            'FNR': fnr\n",
        "        })\n",
        "        print(f\"\\nResults for {name}:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1-Score: {f1:.4f}\")\n",
        "        print(f\"FPR: {fpr:.4f}\")\n",
        "        print(f\"FNR: {fnr:.4f}\")\n",
        "        print(f\"Confusion Matrix:\\n{cm}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error training {name}: {e}\")\n",
        "\n",
        "# Define DNN\n",
        "dnn_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_smote.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile DNN\n",
        "dnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train DNN\n",
        "try:\n",
        "    history = dnn_model.fit(\n",
        "        X_train_smote, y_train_smote,\n",
        "        epochs=20,\n",
        "        batch_size=128,\n",
        "        validation_split=0.2,\n",
        "        verbose=1\n",
        "    )\n",
        "    # Predict\n",
        "    y_pred_proba = dnn_model.predict(X_test)\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
        "    results.append({\n",
        "        'Model': 'DNN',\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'FPR': fpr,\n",
        "        'FNR': fnr\n",
        "    })\n",
        "    print(\"\\nResults for DNN:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"FPR: {fpr:.4f}\")\n",
        "    print(f\"FNR: {fnr:.4f}\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error training DNN: {e}\")\n",
        "\n",
        "# Summarize results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nSummary of Results:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqIxAcSUgOVa",
        "outputId": "cffd4d35-81a3-4bbc-c664-b1dbb4376d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K5VpOGsgTGe",
        "outputId": "475eabe0-cd0c-4a30-e86b-e2d6d72e7206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution of Attack_label:\n",
            "Attack_label\n",
            "1    0.84699\n",
            "0    0.15301\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Absolute Counts:\n",
            "Attack_label\n",
            "1    106924\n",
            "0     19316\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nClass Distribution of Attack_label:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(\"\\nAbsolute Counts:\")\n",
        "print(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-iFDXoBgWuW",
        "outputId": "da93994d-b67c-4d06-8406-21bd6f020ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Random Forest:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "FPR: 0.0000\n",
            "FNR: 0.0000\n",
            "Confusion Matrix:\n",
            "[[ 4985     0]\n",
            " [    0 26575]]\n",
            "\n",
            "Top 10 Feature Importances for Random Forest:\n",
            "                  Feature  Importance\n",
            "0              frame.time    0.137989\n",
            "73         mqtt.topic_0.0    0.127995\n",
            "67  mqtt.conack.flags_0.0    0.123523\n",
            "72           mqtt.topic_0    0.089280\n",
            "70     mqtt.protoname_0.0    0.083043\n",
            "60   dns.qry.name.len_0.0    0.074140\n",
            "66    mqtt.conack.flags_0    0.059626\n",
            "18            tcp.srcport    0.053701\n",
            "59     dns.qry.name.len_0    0.037037\n",
            "15            tcp.options    0.035235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracy: 1.0000 ± 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:921: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Decision Tree:\n",
            "Accuracy: 0.8420\n",
            "Precision: 0.8420\n",
            "Recall: 1.0000\n",
            "F1-Score: 0.9143\n",
            "FPR: 1.0000\n",
            "FNR: 0.0000\n",
            "Confusion Matrix:\n",
            "[[    0  4985]\n",
            " [    0 26575]]\n",
            "\n",
            "Results for KNN:\n",
            "Accuracy: 0.9999\n",
            "Precision: 0.9999\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "FPR: 0.0004\n",
            "FNR: 0.0000\n",
            "Confusion Matrix:\n",
            "[[ 4983     2]\n",
            " [    0 26575]]\n",
            "\n",
            "Results for Logistic Regression:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "FPR: 0.0000\n",
            "FNR: 0.0000\n",
            "Confusion Matrix:\n",
            "[[ 4985     0]\n",
            " [    0 26575]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/data.py:575: UserWarning: Sparse arrays from pandas are converted into dense.\n",
            "  warnings.warn(\"Sparse arrays from pandas are converted into dense.\")\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [19:18:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/data.py:575: UserWarning: Sparse arrays from pandas are converted into dense.\n",
            "  warnings.warn(\"Sparse arrays from pandas are converted into dense.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for XGBoost:\n",
            "Accuracy: 0.1748\n",
            "Precision: 1.0000\n",
            "Recall: 0.0200\n",
            "F1-Score: 0.0393\n",
            "FPR: 0.0000\n",
            "FNR: 0.9800\n",
            "Confusion Matrix:\n",
            "[[ 4985     0]\n",
            " [26043   532]]\n",
            "Epoch 1/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0333 - val_accuracy: 1.0000 - val_loss: 5.3031e-06\n",
            "Epoch 2/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 4.6726e-04 - val_accuracy: 1.0000 - val_loss: 7.4726e-06\n",
            "Epoch 3/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.7447e-04 - val_accuracy: 1.0000 - val_loss: 3.3057e-09\n",
            "Epoch 4/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1847e-04 - val_accuracy: 1.0000 - val_loss: 3.5686e-10\n",
            "Epoch 5/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.9104e-05 - val_accuracy: 1.0000 - val_loss: 6.0121e-12\n",
            "Epoch 6/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5411e-04 - val_accuracy: 1.0000 - val_loss: 8.5877e-13\n",
            "Epoch 7/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.4594e-05 - val_accuracy: 1.0000 - val_loss: 7.8866e-12\n",
            "Epoch 8/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5488e-07 - val_accuracy: 1.0000 - val_loss: 3.6449e-13\n",
            "Epoch 9/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3896e-04 - val_accuracy: 1.0000 - val_loss: 4.6702e-15\n",
            "Epoch 10/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.5174e-08 - val_accuracy: 1.0000 - val_loss: 1.3083e-15\n",
            "Epoch 11/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4869e-04 - val_accuracy: 1.0000 - val_loss: 6.9114e-14\n",
            "Epoch 12/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.9993e-08 - val_accuracy: 1.0000 - val_loss: 3.6691e-15\n",
            "Epoch 13/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.2658e-09 - val_accuracy: 1.0000 - val_loss: 2.1676e-15\n",
            "Epoch 14/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6197e-09 - val_accuracy: 1.0000 - val_loss: 1.4411e-15\n",
            "Epoch 15/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6267e-09 - val_accuracy: 1.0000 - val_loss: 7.9619e-16\n",
            "Epoch 16/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3062e-09 - val_accuracy: 1.0000 - val_loss: 3.6878e-16\n",
            "Epoch 17/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4048e-09 - val_accuracy: 1.0000 - val_loss: 3.4512e-17\n",
            "Epoch 18/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0739e-08 - val_accuracy: 1.0000 - val_loss: 1.2044e-18\n",
            "Epoch 19/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.1852e-10 - val_accuracy: 1.0000 - val_loss: 6.1721e-19\n",
            "Epoch 20/20\n",
            "\u001b[1m1337/1337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.5726e-11 - val_accuracy: 1.0000 - val_loss: 5.0065e-19\n",
            "\u001b[1m987/987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\n",
            "Results for DNN:\n",
            "Accuracy: 0.9999\n",
            "Precision: 0.9999\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "FPR: 0.0004\n",
            "FNR: 0.0000\n",
            "Confusion Matrix:\n",
            "[[ 4983     2]\n",
            " [    0 26575]]\n",
            "\n",
            "Summary of Results:\n",
            "                 Model  Accuracy  Precision    Recall  F1-Score       FPR  \\\n",
            "0        Random Forest  1.000000   1.000000  1.000000  1.000000  0.000000   \n",
            "1        Decision Tree  0.842047   0.842047  1.000000  0.914251  1.000000   \n",
            "2                  KNN  0.999937   0.999925  1.000000  0.999962  0.000401   \n",
            "3  Logistic Regression  1.000000   1.000000  1.000000  1.000000  0.000000   \n",
            "4              XGBoost  0.174810   1.000000  0.020019  0.039252  0.000000   \n",
            "5                  DNN  0.999937   0.999925  1.000000  0.999962  0.000401   \n",
            "\n",
            "        FNR  \n",
            "0  0.000000  \n",
            "1  0.000000  \n",
            "2  0.000000  \n",
            "3  0.000000  \n",
            "4  0.979981  \n",
            "5  0.000000  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sanitize column names\n",
        "def sanitize_column_names(columns):\n",
        "    invalid_chars = ['[', ']', '<', '>', '{', '}', '(', ')', ';', ':', '$']\n",
        "    sanitized = []\n",
        "    for col in columns:\n",
        "        new_col = col\n",
        "        for char in invalid_chars:\n",
        "            new_col = new_col.replace(char, '_')\n",
        "        sanitized.append(new_col)\n",
        "    return sanitized\n",
        "\n",
        "X_train_smote.columns = sanitize_column_names(X_train_smote.columns)\n",
        "X_test.columns = sanitize_column_names(X_test.columns)\n",
        "\n",
        "# Scale features for KNN, Logistic Regression, and DNN\n",
        "scaler = StandardScaler()\n",
        "X_train_smote_scaled = scaler.fit_transform(X_train_smote)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_train_smote_scaled = pd.DataFrame(X_train_smote_scaled, columns=X_train_smote.columns)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=42),  # Pruned\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=10),  # Tuned\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    try:\n",
        "        # Use scaled data for KNN and Logistic Regression\n",
        "        X_train_model = X_train_smote_scaled if name in ['KNN', 'Logistic Regression'] else X_train_smote\n",
        "        X_test_model = X_test_scaled if name in ['KNN', 'Logistic Regression'] else X_test\n",
        "\n",
        "        # Train\n",
        "        model.fit(X_train_model, y_train_smote)\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test_model)\n",
        "        # Metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1-Score': f1,\n",
        "            'FPR': fpr,\n",
        "            'FNR': fnr\n",
        "        })\n",
        "        print(f\"\\nResults for {name}:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1-Score: {f1:.4f}\")\n",
        "        print(f\"FPR: {fpr:.4f}\")\n",
        "        print(f\"FNR: {fnr:.4f}\")\n",
        "        print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "        # Random Forest: Feature importance and cross-validation\n",
        "        if name == 'Random Forest':\n",
        "            importances = pd.DataFrame({\n",
        "                'Feature': X_train_smote.columns,\n",
        "                'Importance': model.feature_importances_\n",
        "            }).sort_values('Importance', ascending=False)\n",
        "            print(f\"\\nTop 10 Feature Importances for {name}:\")\n",
        "            print(importances.head(10))\n",
        "            cv_scores = cross_val_score(model, X_train_smote, y_train_smote, cv=5, scoring='accuracy')\n",
        "            print(f\"Cross-Validation Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error training {name}: {e}\")\n",
        "\n",
        "# Define DNN with Input layer\n",
        "dnn_model = Sequential([\n",
        "    Input(shape=(X_train_smote.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile DNN\n",
        "dnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train DNN on scaled data\n",
        "try:\n",
        "    history = dnn_model.fit(\n",
        "        X_train_smote_scaled, y_train_smote,\n",
        "        epochs=20,\n",
        "        batch_size=128,\n",
        "        validation_split=0.2,\n",
        "        verbose=1\n",
        "    )\n",
        "    # Predict\n",
        "    y_pred_proba = dnn_model.predict(X_test_scaled)\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
        "    results.append({\n",
        "        'Model': 'DNN',\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'FPR': fpr,\n",
        "        'FNR': fnr\n",
        "    })\n",
        "    print(\"\\nResults for DNN:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "    print(f\"FPR: {fpr:.4f}\")\n",
        "    print(f\"FNR: {fnr:.4f}\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error training DNN: {e}\")\n",
        "\n",
        "# Summarize results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nSummary of Results:\")\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52W8QZb5mfuZ",
        "outputId": "622577c7-a6d8-4767-e69b-2915f5f5c999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sklearn.preprocessing._encoders\n"
          ]
        }
      ],
      "source": [
        "print(OneHotEncoder.__module__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "YDxDEFmxly21",
        "outputId": "471b5ece-cc9c-4250-e7dd-d65a541b6c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['mqtt.conackAdams', 'mqtt.metres', 'mqtt.config.cleans', 'mqtt.config'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a2ede44db6f8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# One-hot encoding for low-cardinality features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0monehot_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0monehot_encoded_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlow_cardinality\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0monehot_encoded_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlow_cardinality\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0monehot_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow_cardinality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['mqtt.conackAdams', 'mqtt.metres', 'mqtt.config.cleans', 'mqtt.config'] not in index\""
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZwUUHYyHx-2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbM6YTFouZTQYV2OIWsU+F",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}